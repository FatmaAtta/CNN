{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatmaAtta/CNN/blob/main/SL_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhdUH3RBqUs9",
        "outputId": "a33eaf61-5816-4e6d-cbbe-f38790f50b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Rules\n",
        "### Each step, you test a specific parameter first then after finding the best value, use it in the next steps to find the best of the other parameters\n",
        "\n",
        "*   Data must be shuffled first\n",
        "*   batch size > 30\n",
        "*   start with RelU\n",
        "* number of layers > 3\n",
        "* 2D max pooling layer - 2x2 stride - 2x2 kernel size\n",
        "* optimizer -> stochastic gradient descent with any initial learning rate\n",
        "* do not use more than 3 CNN layers in any model\n",
        "* do not use more than 4 FC (fully connected) layers\n",
        "* start with batch size = 32 or 64 (how many samples model looks at before updating weights)\n",
        "* number of epochs >= 10  and <=25 maybe (an epoch is one complete pass on the data)\n",
        "* test with double the batch size AND ( triple OR 4 times)\n",
        "* use atleast 3 other activation functions\n",
        "* with best settings reached -> try 2 more optimizers\n",
        "* put dropout layer anywhere and test 2 different places and different dropout rates\n",
        "* data input should be 28x28\n",
        "* output layer size = 10 (corresponding to the different classes)\n",
        "* mnist dataset\n",
        "* cross entropy loss\n",
        "\n"
      ],
      "metadata": {
        "id": "XLUyHUpjQWeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train images shape:       \",x_train.shape)\n",
        "print(\"Train labels shape:       \",y_train.shape)\n",
        "print(\"Validation images shape:  \",x_valid.shape)\n",
        "print(\"Validation labels shape:  \",y_valid.shape)\n",
        "print(\"Test images shape:        \",x_test.shape)\n",
        "print(\"Test labels shape:        \",y_test.shape)"
      ],
      "metadata": {
        "id": "UKUOBiISs_Ns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb9dc4d7-059f-473c-ff5d-7ee1cb46b8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Train images shape:        (48000, 28, 28)\n",
            "Train labels shape:        (48000,)\n",
            "Validation images shape:   (12000, 28, 28)\n",
            "Validation labels shape:   (12000,)\n",
            "Test images shape:         (10000, 28, 28)\n",
            "Test labels shape:         (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mqyv5OT6u3Sn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_valid = x_valid.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "mean = np.mean(x_train)\n",
        "std = np.std(x_train)\n",
        "\n",
        "x_train = (x_train-mean)/(std + 1e-7)\n",
        "x_valid = (x_valid-mean)/(std + 1e-7)\n",
        "x_test = (x_test-mean)/(std + 1e-7)\n",
        "\n",
        "y_train = to_categorical(y_train,10)\n",
        "y_valid = to_categorical(y_valid, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "4-pHounPu85R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANN Model"
      ],
      "metadata": {
        "id": "v67kS9bqRJKK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDZXbm4BP_fy",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=x_train.shape[1:]),\n",
        "    Dropout(0.2),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 12\n",
        "learning_rate = 0.001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate,beta_1= 0.9 ,beta_2= 0.999, epsilon=1e-07)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Test and measure time\n",
        "train_start = time.time()\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_valid, y_valid),\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[reduce_lr, early_stopping],\n",
        "    verbose=2\n",
        ")\n",
        "train_end = time.time()\n",
        "avg_train_time = (train_end - train_start) / epochs\n",
        "\n",
        "test_times = []\n",
        "for _ in range(epochs):\n",
        "    start = time.time()\n",
        "    model.evaluate(x_test, y_test, verbose=0)\n",
        "    end = time.time()\n",
        "    test_times.append(end - start)\n",
        "avg_test_time = np.mean(test_times)\n",
        "\n",
        "\n",
        "final_test_loss, final_test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print(\"\\n--- ANN Results ---\")\n",
        "print(f\"Final Test Accuracy: {final_test_acc:.4f}\")\n",
        "print(\"Validation Accuracy per 1st 5 Epoch:\", [f\"{acc:.4f}\" for acc in history.history['val_accuracy'][:5]])\n",
        "print(f\"Total Parameters: {model.count_params()}\")\n",
        "print(f\"Average Training Time per Epoch: {avg_train_time:.4f} seconds\")\n",
        "print(f\"Average Testing Time per Epoch: {avg_test_time:.4f} seconds\")\n",
        "print(f\"Layers: Input(784) -> Dense(512, relu) -> Dropout(0.2) -> Dense(256, relu) -> Dense(10, softmax)\")\n",
        "print(\"Learning Rate Used:\", learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Model"
      ],
      "metadata": {
        "id": "wmq71p8TROB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
        "\n",
        "x_train_svm, _, y_train_svm, _ = train_test_split(x_train, y_train, train_size=8000, stratify=y_train, random_state=42)\n",
        "x_test_svm, _, y_test_svm, _ = train_test_split(x_test, y_test, train_size=2000, stratify=y_test, random_state=42)\n"
      ],
      "metadata": {
        "id": "mXgCBP3AwG-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', gamma='scale', C=5))\n",
        "start_train = time.time()\n",
        "clf.fit(x_train_svm, y_train_svm)\n",
        "end_train = time.time()\n",
        "train_time = end_train - start_train\n",
        "\n",
        "start_test = time.time()\n",
        "y_pred = clf.predict(x_test_svm)\n",
        "end_test = time.time()\n",
        "test_time = end_test - start_test\n",
        "\n",
        "acc = accuracy_score(y_test_svm, y_pred)\n",
        "\n",
        "print(\"\\n--- SVM Results ---\")\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Training Time: {train_time:.2f} seconds\")\n",
        "print(f\"Testing Time: {test_time:.4f} seconds\")"
      ],
      "metadata": {
        "id": "sfqtnqBoRR4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN\n",
        "* use RelU for now\n",
        "* 3 layers minimum\n",
        "* 2D MAX pooling after at least one layer, 2x2 stride, 2x2 kernel\n",
        "* choose good starting epoch\n",
        "* optimizer -> SGD\n",
        "* start with any learning rate\n",
        "* test different learning rates\n",
        "* start with batch size = 32, 64"
      ],
      "metadata": {
        "id": "BinHAafhRSHi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qxuq7t03TxST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing different learning rates"
      ],
      "metadata": {
        "id": "rbzCyUjpTxoB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tcC84uYfWblL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing different number of CNN layers and CNN parameters\n",
        "###Testing different number of FC layers\n"
      ],
      "metadata": {
        "id": "2V45RsGTWb-i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VtRUs7DzbTLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### batch size = 2b"
      ],
      "metadata": {
        "id": "Gaj7rlWJZU97"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XqaL2gF_bRYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##activation function 1"
      ],
      "metadata": {
        "id": "m5f2qXJxaEN7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TecZzfXHbRAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## activation function 2"
      ],
      "metadata": {
        "id": "3mIJSMUzaaID"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YzHmcPMSbQrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#activation function 3\n"
      ],
      "metadata": {
        "id": "0I6wx1feafiz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4cn8RQZbbP9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## optimizer 1"
      ],
      "metadata": {
        "id": "SP1f34S8am4r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-OQV3A5bMhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##optimizer 2\n",
        "\n"
      ],
      "metadata": {
        "id": "dQTS_xqdapLj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "huQFqSE9bOOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dropout layer place 1"
      ],
      "metadata": {
        "id": "OY056GA9a49D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8f044l3bN9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dropout layer place 2"
      ],
      "metadata": {
        "id": "2V7cjDufbEDU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfAX0jp_bPL6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}